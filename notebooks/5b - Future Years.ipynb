{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPSA-GB can model the GB power system  by solving a network constrained Linear Optimal Power Flow (LOPF) problem. This notebook shows the example application of a future 3 day period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "src_path = os.environ.get('PROJECT_SRC')\n",
    "os.chdir(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import data_reader_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the required inputs for the LOPF: the start, end and year of simulation, and the timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv files for import\n",
    "#start = '2040-02-28 00:00:00'\n",
    "#end = '2040-03-01 23:30:00'\n",
    "# year of simulation\n",
    "#year = int(start[0:4])\n",
    "# time step as fraction of hour\n",
    "#time_step = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv files for import\n",
    "start = '2050-01-01 00:00:00'\n",
    "end = '2050-12-31 23:00:00'\n",
    "# year of simulation\n",
    "year = int(start[0:4])\n",
    "# time step as fraction of hour\n",
    "time_step = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose from one of the National Grid Future Energy Scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'Leading The Way'\n",
    "# scenario = 'Consumer Transformation'\n",
    "# scenario = 'System Transformation'\n",
    "# scenario = 'Steady Progression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a baseline year (from 2010-2020). The baseline year determines which historical load profile and weather dataset is used for the future year modelled. The National Grid FES modellers used 2012 as their baseline year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_baseline = 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_reader_writer is a script written to read in data from the various sources and write csv files in the format required for populating a PyPSA network object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salene\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:741: PerformanceWarning: Non-vectorized DateOffset being applied to Series or DatetimeIndex\n",
      "  warnings.warn(\n",
      "C:\\Users\\salene\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\salene\\Desktop\\WholeEnergySystemModelling_New\\PyPSA-GB\\PyPSA-GB\\interconnectors.py:207: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  df_FES = df_FES[~df_FES.Variable.str.contains('(TWh)')]\n"
     ]
    }
   ],
   "source": [
    "data_reader_writer.data_writer(start, end, time_step, year, demand_dataset='eload', year_baseline=year_baseline,\n",
    "                               scenario=scenario, FES=2022, merge_generators=True, scale_to_peak=True,\n",
    "                               networkmodel='Reduced', P2G=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypsa.io:Importing network from PyPSA version v? while current version is v0.23.0. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n",
      "INFO:pypsa.components:Applying weightings to all columns of `snapshot_weightings`\n",
      "INFO:pypsa.io:Imported network LOPF_data_heat_FES has buses, generators, lines, links, loads, storage_units\n"
     ]
    }
   ],
   "source": [
    "network = pypsa.Network()\n",
    "#network.import_from_csv_folder('LOPF_data')\n",
    "network.import_from_csv_folder('LOPF_data_heat_FES')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links need to be scaled up to accomadate for future generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_factor = 4\n",
    "network.lines.s_max_pu *= contingency_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.linopf:Prepare linear problem\n",
      "INFO:pypsa.linopf:Total preparation time: 117.36s\n",
      "INFO:pypsa.linopf:Solve linear problem using Gurobi solver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-29\n",
      "Read LP format model from file C:\\Users\\salene\\AppData\\Local\\Temp\\pypsa-problem-cotw5nc1.lp\n",
      "Reading time = 69.02 seconds\n",
      "obj: 21198278 rows, 5825430 columns, 38095363 nonzeros\n",
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (win64)\n",
      "\n",
      "CPU model: 11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 21198278 rows, 5825430 columns and 38095363 nonzeros\n",
      "Model fingerprint: 0x47905c10\n",
      "Coefficient statistics:\n",
      "  Matrix range     [6e-05, 3e+03]\n",
      "  Objective range  [1e+00, 1e+09]\n",
      "  Bounds range     [1e+07, 1e+07]\n",
      "  RHS range        [1e-06, 1e+09]\n",
      "Presolve removed 18911930 rows and 736970 columns (presolve time = 6s) ...\n",
      "Presolve removed 18911930 rows and 2298305 columns (presolve time = 10s) ...\n",
      "Presolve removed 19534599 rows and 2920974 columns (presolve time = 15s) ...\n",
      "Presolve removed 19534599 rows and 2920974 columns (presolve time = 24s) ...\n",
      "Presolve removed 19534599 rows and 2920974 columns (presolve time = 25s) ...\n",
      "Presolve removed 19587153 rows and 2924255 columns\n",
      "Presolve time: 28.20s\n",
      "Presolved: 1611125 rows, 2953729 columns, 7090282 nonzeros\n",
      "\n",
      "Concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Elapsed ordering time = 7s\n",
      "Ordering time: 9.01s\n",
      "\n",
      "Barrier performed 0 iterations in 38.70 seconds (25.44 work units)\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Solved in 58720 iterations and 38.91 seconds (31.10 work units)\n",
      "Infeasible or unbounded model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypsa.linopf:Optimization failed with status warning and termination condition infeasible or unbounded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('warning', 'infeasible or unbounded')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.lopf(network.snapshots, solver_name=\"gurobi\", pyomo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power output by generation type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the generators by the carrier, and print their summed power outputs over the simulation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Biomass (dedicated)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Biomass (dedicated)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m interconnector_export \u001b[38;5;241m=\u001b[39m exp[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInterconnectors Export\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# group biomass stuff\u001b[39;00m\n\u001b[0;32m     25\u001b[0m p_by_carrier[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBiomass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mp_by_carrier\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBiomass (dedicated)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m p_by_carrier[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBiomass (co-firing)\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# rename the hydro bit\u001b[39;00m\n\u001b[0;32m     29\u001b[0m p_by_carrier \u001b[38;5;241m=\u001b[39m p_by_carrier\u001b[38;5;241m.\u001b[39mrename(\n\u001b[0;32m     30\u001b[0m     columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLarge Hydro\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHydro\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\frame.py:3455\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3455\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3457\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Biomass (dedicated)'"
     ]
    }
   ],
   "source": [
    "p_by_carrier = network.generators_t.p.groupby(\n",
    "    network.generators.carrier, axis=1).sum()\n",
    "\n",
    "storage_by_carrier = network.storage_units_t.p.groupby(\n",
    "    network.storage_units.carrier, axis=1).sum()\n",
    "\n",
    "# to show on graph set the negative storage values to zero\n",
    "storage_by_carrier[storage_by_carrier < 0] = 0\n",
    "\n",
    "p_by_carrier = pd.concat([p_by_carrier, storage_by_carrier], axis=1)\n",
    "\n",
    "imp = network.links_t.p0.copy()\n",
    "imp[imp < 0] = 0\n",
    "imp['Interconnectors Import'] = imp.sum(axis=1)\n",
    "interconnector_import = imp[['Interconnectors Import']]\n",
    "\n",
    "p_by_carrier = pd.concat([p_by_carrier, interconnector_import], axis=1)\n",
    "\n",
    "exp = network.links_t.p0.copy()\n",
    "exp[exp > 0] = 0\n",
    "exp['Interconnectors Export'] = exp.sum(axis=1)\n",
    "interconnector_export = exp[['Interconnectors Export']]\n",
    "\n",
    "# group biomass stuff\n",
    "p_by_carrier['Biomass'] = (\n",
    "    p_by_carrier['Biomass (dedicated)'] + p_by_carrier['Biomass (co-firing)'])\n",
    "\n",
    "# rename the hydro bit\n",
    "p_by_carrier = p_by_carrier.rename(\n",
    "    columns={'Large Hydro': 'Hydro'})\n",
    "p_by_carrier = p_by_carrier.rename(\n",
    "    columns={'Interconnector': 'Interconnectors Import'})\n",
    "\n",
    "generators_p_nom = network.generators.p_nom.groupby(\n",
    "    network.generators.carrier).sum().sort_values()\n",
    "if year > 2020:\n",
    "    generators_p_nom.drop('Unmet Load', inplace=True)\n",
    "generators_p_nom.drop(generators_p_nom[generators_p_nom < 50].index, inplace=True)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "# bar chart\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(generators_p_nom.index, generators_p_nom.values / 1000)\n",
    "plt.xticks(generators_p_nom.index, rotation=90)\n",
    "plt.ylabel('GW')\n",
    "plt.grid(color='grey', linewidth=1, axis='both', alpha=0.5)\n",
    "plt.title('Installed capacity in year ' + str(year))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the power output of the different generation types..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Nuclear\", 'Biomass',\n",
    "        'Waste', \"Oil\", \"Natural Gas\",\n",
    "        'Hydrogen', 'CCS Gas', 'CCS Biomass',\n",
    "        \"Pumped Storage Hydroelectric\", 'Hydro',\n",
    "        'Battery', 'Compressed Air', 'Liquid Air',\n",
    "        \"Wind Offshore\", 'Wind Onshore', 'Solar Photovoltaics',\n",
    "        'Interconnectors Import', 'Unmet Load'\n",
    "        ]\n",
    "\n",
    "p_by_carrier = p_by_carrier[cols]\n",
    "\n",
    "p_by_carrier.drop(\n",
    "    (p_by_carrier.max()[p_by_carrier.max() < 50.0]).index,\n",
    "    axis=1, inplace=True)\n",
    "\n",
    "colors = {\"Coal\": \"grey\",\n",
    "          \"Diesel/Gas oil\": \"black\",\n",
    "          \"Diesel/gas Diesel/Gas oil\": \"black\",\n",
    "          'Oil': 'black',\n",
    "          'Unmet Load': 'black',\n",
    "          'Anaerobic Digestion': 'green',\n",
    "          'Waste': 'chocolate',\n",
    "          'Sewage Sludge Digestion': 'green',\n",
    "          'Landfill Gas': 'green',\n",
    "          'Biomass (dedicated)': 'green',\n",
    "          'Biomass (co-firing)': 'green',\n",
    "          'Biomass': 'green',\n",
    "          'CCS Biomass': 'darkgreen',\n",
    "          'Interconnectors Import': 'pink',\n",
    "          'B6 import': 'pink',\n",
    "          \"Sour gas\": \"lightcoral\",\n",
    "          \"Natural Gas\": \"lightcoral\",\n",
    "          'CCS Gas': \"lightcoral\",\n",
    "          'Hydrogen': \"deeppink\",\n",
    "          \"Nuclear\": \"orange\",\n",
    "          'Shoreline Wave': 'aqua',\n",
    "          'Tidal Barrage and Tidal Stream': 'aqua',\n",
    "          'Hydro': \"turquoise\",\n",
    "          \"Large Hydro\": \"turquoise\",\n",
    "          \"Small Hydro\": \"turquoise\",\n",
    "          \"Pumped Storage Hydroelectric\": \"darkturquoise\",\n",
    "          'Battery': 'lime',\n",
    "          'Compressed Air': 'greenyellow',\n",
    "          'Liquid Air': 'lawngreen',\n",
    "          \"Wind Offshore\": \"lightskyblue\",\n",
    "          'Wind Onshore': 'deepskyblue',\n",
    "          'Solar Photovoltaics': 'yellow'}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "(p_by_carrier / 1e3).plot(\n",
    "    kind=\"area\", ax=ax, linewidth=0,\n",
    "    color=[colors[col] for col in p_by_carrier.columns])\n",
    "\n",
    "# # stacked area plot of negative values, prepend column names with '_' such that they don't appear in the legend\n",
    "# (interconnector_export / 1e3).plot.area(ax=ax, stacked=True, linewidth=0.)\n",
    "# # rescale the y axis\n",
    "# ax.set_ylim([(interconnector_export / 1e3).sum(axis=1).min(), (p_by_carrier / 1e3).sum(axis=1).max()])\n",
    "\n",
    "# Shrink current axis's height by 10% on the bottom\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                 box.width, box.height * 0.9])\n",
    "\n",
    "# Put a legend below current axis\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.52, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "ax.set_ylabel(\"GW\")\n",
    "\n",
    "ax.set_xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the pumped hydro dispatch and state of charge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "\n",
    "p_storage = network.storage_units_t.p.sum(axis=1)\n",
    "state_of_charge = network.storage_units_t.state_of_charge.sum(axis=1)\n",
    "p_storage.plot(label=\"Pumped hydro dispatch\", ax=ax, linewidth=3)\n",
    "state_of_charge.plot(label=\"State of charge\", ax=ax, linewidth=3)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"MWh\")\n",
    "ax.set_xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting line loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the line loading stats and graph..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = network.snapshots[139]\n",
    "\n",
    "print(\"With the linear load flow, there is the following per unit loading:\")\n",
    "loading = network.lines_t.p0.loc[now] / network.lines.s_nom\n",
    "loading.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "fig.set_size_inches(15, 17)\n",
    "\n",
    "network.plot(ax=ax, line_colors=abs(loading), line_cmap=plt.cm.jet, title=\"Line loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting locational marginal prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "network.plot(ax=ax, line_widths=pd.Series(0.5, network.lines.index))\n",
    "plt.hexbin(network.buses.x, network.buses.y,\n",
    "           gridsize=20,\n",
    "           C=network.buses_t.marginal_price.loc[now],\n",
    "           cmap=plt.cm.jet)\n",
    "\n",
    "# for some reason the colorbar only works with graphs plt.plot\n",
    "# and must be attached plt.colorbar\n",
    "\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Locational Marginal Price (£/MWh)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.buses_t.marginal_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting curtailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier = \"Wind Onshore\"\n",
    "\n",
    "capacity = network.generators.groupby(\"carrier\").sum().at[carrier, \"p_nom\"]\n",
    "p_available = network.generators_t.p_max_pu.multiply(network.generators[\"p_nom\"])\n",
    "p_available_by_carrier = p_available.groupby(network.generators.carrier, axis=1).sum()\n",
    "p_curtailed_by_carrier = p_available_by_carrier - p_by_carrier\n",
    "p_df = pd.DataFrame({carrier + \" available\": p_available_by_carrier[carrier],\n",
    "                     carrier + \" dispatched\": p_by_carrier[carrier],\n",
    "                     carrier + \" curtailed\": p_curtailed_by_carrier[carrier]})\n",
    "\n",
    "p_df[carrier + \" capacity\"] = capacity\n",
    "p_df[\"Wind Onshore curtailed\"][p_df[\"Wind Onshore curtailed\"] < 0.] = 0.\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "p_df[[carrier + \" dispatched\", carrier + \" curtailed\"]].plot(kind=\"area\", ax=ax, linewidth=0)\n",
    "# p_df[[carrier + \" available\", carrier + \" capacity\"]].plot(ax=ax, linewidth=0)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Power [MW]\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Wind Offshore Deeside'\n",
    "type(network.generators_t.p_max_pu[name])\n",
    "#My_network.generators.groupby(\"carrier\").sum().at[carrier, \"p_nom\"]\n",
    "#p_available = My_network.generators_t.p_max_pu\n",
    "wind_offshore_deeside_available=network.generators.at[name,'p_nom']*network.generators_t.p_max_pu[name]\n",
    "# next find the dispatched power at deeside\n",
    "dispatched_wind_offshore_deeside=network.generators_t.p['Wind Offshore Deeside']\n",
    "curtailed_wind_offshore_deeside=wind_offshore_deeside_available-dispatched_wind_offshore_deeside\n",
    "\n",
    "capacity = network.generators.at[name, \"p_nom\"]\n",
    "capacity_t=pd.Series(capacity,index=network.generators_t.p['Wind Offshore Deeside'].index,name='Wind Offshore Capacity')\n",
    "capacity_t\n",
    "\n",
    "\n",
    "wind_offshore_deeside_df=pd.concat([capacity_t,dispatched_wind_offshore_deeside.rename('Wind Offshore Deeside Dispatched'),wind_offshore_deeside_available.rename('Wind Offshore Deeside Available')],axis=1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "wind_offshore_deeside_df.plot(ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Power [MW]\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curtailed_wind_offshore_deeside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a362b17abcd2c031329e78f98409aa17fadf72082aebdc1d10da213122c16a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
